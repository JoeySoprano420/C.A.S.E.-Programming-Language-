Fn tokenize "string src" (
  Print "Starting lexical analysis..." [end]

  let i = 0
  let line = 1
  let tokens = []

  loop "i < src.length()" {
    if src[i] == '\n' {
      line = line + 1
      i = i + 1
    } else if src[i] == ' ' {
      i = i + 1
    } else if src[i] == '\t' {
      i = i + 1
    } else if src[i] == '/' {
      if src[i+1] == '/' {
        loop "i < src.length() && src[i] != '\n'" {
          i = i + 1
        } [end]
      } else {
        call push tokens "SYMBOL" "/" [end]
        i = i + 1
      }
    } else if isLetter src[i] {
      let start = i
      loop "isAlphaNum(src[i])" { i = i + 1 } [end]
      let ident = substring src start i
      if isKeyword ident {
        call push tokens "KEYWORD" ident [end]
      } else {
        call push tokens "IDENT" ident [end]
      }
    } else if src[i] == '"' {
      i = i + 1
      let acc = ""
      loop "i < src.length() && src[i] != '\"'" {
        acc = acc + src[i]
        i = i + 1
      } [end]
      call push tokens "STRING" acc [end]
      i = i + 1
    } else if isDigit src[i] {
      let start = i
      loop "isDigit(src[i])" { i = i + 1 } [end]
      let num = substring src start i
      call push tokens "NUMBER" num [end]
    } else {
      call push tokens "SYMBOL" src[i] [end]
      i = i + 1
    }
  } [end]

  call push tokens "END" "" [end]
  ret tokens
) [end]


